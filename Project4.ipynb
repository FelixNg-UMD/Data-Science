{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -q transformers"
      ],
      "metadata": {
        "id": "5d2CY42ShmFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "profs = [\"Maksym Morawski\", \"Cliff Bakalian\", \"Ilchul Yoon\", \"Clyde Kruskal\"]\n",
        "all_reviews = []\n",
        "url = \"https://planetterp.com/api/v1/professor\"\n",
        "for prof in profs:\n",
        "    response = requests.get(url, params={\"name\": prof, \"reviews\": \"true\"})\n",
        "    data = response.json()\n",
        "    reviews = data.get(\"reviews\", [])\n",
        "    all_reviews.extend(reviews)\n",
        "\n",
        "df = pd.DataFrame(all_reviews)\n",
        "print(df.tail())\n",
        "\n",
        "# Use sentiment analysis of students' reviews\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
        "\n",
        "reviews = df['review'].tolist()\n",
        "indexes_to_drop = []\n",
        "sentiments = []\n",
        "\n",
        "for idx, review in enumerate(df['review']):\n",
        "    try:\n",
        "        result = pipe(review, truncation=True)[0]\n",
        "        sentiments.append(result['label'])\n",
        "    except Exception as e:\n",
        "        print(f\"Dropping review at index {idx} due to error: {e}\")\n",
        "        indexes_to_drop.append(idx)\n",
        "        sentiments.append(None)\n",
        "\n",
        "# Drop the bad reviews\n",
        "df.drop(index=indexes_to_drop, inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Only keep valid sentiments\n",
        "df['sentiment'] = [s for s in sentiments if s is not None]\n",
        "\n",
        "# Sentiment-to-star\n",
        "sentiment_to_star = {\n",
        "    \"positive\": 3,\n",
        "    \"neutral\": 2,\n",
        "    \"negative\": 1\n",
        "}\n",
        "df['sentiment_to_star'] = df['sentiment'].map(sentiment_to_star)\n",
        "df = df.dropna(subset=['sentiment_to_star'])\n",
        "\n",
        "\n",
        "# Data cleaning and malnipulation\n",
        "filtered_data = df.dropna(subset=['rating', 'expected_grade'])\n",
        "valid_grades = {'A+', 'A', 'A-', 'B+', 'B', 'B-', 'C+', 'C', 'C-', 'D+', 'D', 'D-', 'F', 'XF', 'W', 'P'}\n",
        "filtered_data = filtered_data[filtered_data['expected_grade'].isin(valid_grades)]\n",
        "\n",
        "grade_to_number = {'A+': 4.0, 'A': 4.0, 'A-': 3.7, 'B+': 3.3, 'B': 3.0, 'B-': 2.7, 'C+': 2.3, 'C': 2.0, 'C-': 1.7, 'D+': 1.3, 'D': 1.0, 'D-': 0.7, 'F': 0.0, 'XF': 0.0, 'W': 0.0, 'P': 0.0}\n",
        "filtered_data['grade_number'] = filtered_data['expected_grade'].map(grade_to_number)\n",
        "\n",
        "filtered_data['review_length'] = filtered_data['review'].apply(lambda x: len(str(x)))\n",
        "\n",
        "# convert rating to good, bad, or neutral for classify\n",
        "def categorize_rating(rating):\n",
        "    if rating > 3:\n",
        "        return 'good'\n",
        "    elif rating < 3:\n",
        "        return 'bad'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "filtered_data['rating_category'] = filtered_data['rating'].apply(categorize_rating)\n",
        "\n",
        "\n",
        "print(filtered_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWCtdR-n2c_1",
        "outputId": "5476f465-c539-47ae-98f6-885cb4e1024b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         professor   course  \\\n",
            "594  Clyde Kruskal  CMSC451   \n",
            "595  Clyde Kruskal  CMSC351   \n",
            "596  Clyde Kruskal  CMSC351   \n",
            "597  Clyde Kruskal  CMSC351   \n",
            "598  Clyde Kruskal  CMSC351   \n",
            "\n",
            "                                                review  rating expected_grade  \\\n",
            "594  I would recommend him for 451. He's very disor...       4              A   \n",
            "595  Does not give syllabus for class. Does not tel...       2             A-   \n",
            "596  I was scared shitless before starting this cla...       4             A-   \n",
            "597  very hard professor, but u wont learn jacks**t...       2              B   \n",
            "598  VERY VERY VERY MESSY CLASS. AVOID IF CAN. ITS ...       1              C   \n",
            "\n",
            "                         created  \n",
            "594  2024-12-23T19:44:19.894218Z  \n",
            "595  2024-12-24T17:29:23.721410Z  \n",
            "596  2025-02-06T19:10:50.448880Z  \n",
            "597  2025-04-02T19:45:52.387020Z  \n",
            "598  2025-04-11T14:29:47.994442Z  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropping review at index 19 due to error: The expanded size of the tensor (729) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 729].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 79 due to error: The expanded size of the tensor (1121) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 1121].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 93 due to error: The expanded size of the tensor (679) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 679].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 94 due to error: The expanded size of the tensor (577) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 577].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 106 due to error: The expanded size of the tensor (614) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 614].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 148 due to error: The expanded size of the tensor (1402) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 1402].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 154 due to error: The expanded size of the tensor (739) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 739].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 182 due to error: The expanded size of the tensor (1363) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 1363].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 196 due to error: The expanded size of the tensor (835) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 835].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 252 due to error: The expanded size of the tensor (688) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 688].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 302 due to error: The expanded size of the tensor (556) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 556].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 314 due to error: The expanded size of the tensor (522) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 522].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 321 due to error: The expanded size of the tensor (697) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 697].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 323 due to error: The expanded size of the tensor (888) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 888].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 339 due to error: The expanded size of the tensor (553) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 553].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 348 due to error: The expanded size of the tensor (981) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 981].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 366 due to error: The expanded size of the tensor (523) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 523].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 416 due to error: The expanded size of the tensor (840) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 840].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 420 due to error: The expanded size of the tensor (525) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 525].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 429 due to error: The expanded size of the tensor (1080) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 1080].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 450 due to error: The expanded size of the tensor (529) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 529].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 488 due to error: The expanded size of the tensor (960) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 960].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 489 due to error: The expanded size of the tensor (516) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 516].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 509 due to error: The expanded size of the tensor (661) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 661].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 530 due to error: The expanded size of the tensor (667) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 667].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 533 due to error: The expanded size of the tensor (563) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 563].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 537 due to error: The expanded size of the tensor (637) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 637].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 564 due to error: The expanded size of the tensor (604) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 604].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 570 due to error: The expanded size of the tensor (560) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 560].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 584 due to error: The expanded size of the tensor (898) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 898].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 585 due to error: The expanded size of the tensor (537) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 537].  Tensor sizes: [1, 514]\n",
            "Dropping review at index 587 due to error: The expanded size of the tensor (1060) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 1060].  Tensor sizes: [1, 514]\n",
            "         professor   course  \\\n",
            "0  Maksym Morawski  CMSC320   \n",
            "1  Maksym Morawski  CMSC320   \n",
            "4  Maksym Morawski  CMSC320   \n",
            "6  Maksym Morawski  CMSC320   \n",
            "7  Maksym Morawski  CMSC320   \n",
            "\n",
            "                                              review  rating expected_grade  \\\n",
            "0  DO NOT take this class with Maksym Moraswki. H...       1             B-   \n",
            "1  Love how the rate my prof ratings are so much ...       5              A   \n",
            "4  Classroom lectures, while interesting, aren't ...       1             C+   \n",
            "6                  I learned nothing from his class.       1              B   \n",
            "7  Horrible professor contingent on making your l...       1             A-   \n",
            "\n",
            "                       created sentiment  sentiment_to_star  grade_number  \\\n",
            "0  2022-10-17T20:55:12.884947Z  negative                  1           2.7   \n",
            "1  2022-10-19T19:38:30.116079Z  positive                  3           4.0   \n",
            "4  2022-10-27T19:51:36.707432Z  negative                  1           2.3   \n",
            "6  2022-11-02T20:31:40.656533Z  negative                  1           3.0   \n",
            "7  2022-11-07T02:32:08.936343Z  negative                  1           3.7   \n",
            "\n",
            "   review_length rating_category  \n",
            "0            173             bad  \n",
            "1            424            good  \n",
            "4            306             bad  \n",
            "6             33             bad  \n",
            "7            405             bad  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split 3 profs for training and 1 for testing\n",
        "train_profs = [\"Cliff Bakalian\", \"Ilchul Yoon\", \"Clyde Kruskal\"]\n",
        "test_prof = [\"Maksym Morawski\"]\n",
        "\n",
        "train_data = filtered_data[filtered_data['professor'].isin(train_profs)]\n",
        "test_data = filtered_data[filtered_data['professor'].isin(test_prof)]\n"
      ],
      "metadata": {
        "id": "GkrNM5WR6zG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from tabulate import tabulate\n",
        "feature_sets = [\n",
        "    ['sentiment_to_star'],\n",
        "    ['review_length'],\n",
        "    ['grade_number'],\n",
        "    ['sentiment_to_star', 'review_length'],\n",
        "    ['sentiment_to_star', 'grade_number'],\n",
        "    ['review_length', 'grade_number'],\n",
        "    ['sentiment_to_star', 'review_length', 'grade_number']\n",
        "]\n",
        "actual_counts = test_data['rating_category'].value_counts()\n",
        "results = []\n",
        "for features in feature_sets:\n",
        "    X_train = train_data[features]\n",
        "    X_test = test_data[features]\n",
        "    y_train = train_data['rating_category']\n",
        "    y_test = test_data['rating_category']\n",
        "\n",
        "    model = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    predicted_rating = model.predict(X_test)\n",
        "    pred_counts = pd.Series(predicted_rating).value_counts()\n",
        "    accuracy = accuracy_score(y_test, predicted_rating)\n",
        "    results.append({\n",
        "     'Features': features,\n",
        "     'Accuracy': round(accuracy, 3),\n",
        "     'Pred Good': pred_counts.get('good', 0),\n",
        "     'Pred Neutral': pred_counts.get('neutral', 0),\n",
        "     'Pred Bad': pred_counts.get('bad', 0),\n",
        "     'Actual Good': actual_counts.get('good', 0),\n",
        "     'Actual Neutral': actual_counts.get('neutral', 0),\n",
        "     'Actual Bad': actual_counts.get('bad', 0),\n",
        "})\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by='Accuracy', ascending=False)\n",
        "print(tabulate(results_df, headers='keys', tablefmt='pretty', showindex=False))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-b7ky3awCcb",
        "outputId": "ca5a86eb-34ed-45d6-b009-892438cdf4f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------+----------+-----------+--------------+----------+-------------+----------------+------------+\n",
            "|                        Features                        | Accuracy | Pred Good | Pred Neutral | Pred Bad | Actual Good | Actual Neutral | Actual Bad |\n",
            "+--------------------------------------------------------+----------+-----------+--------------+----------+-------------+----------------+------------+\n",
            "|                 ['sentiment_to_star']                  |  0.691   |    57     |      0       |   105    |     72      |       22       |     68     |\n",
            "|         ['sentiment_to_star', 'grade_number']          |  0.691   |    56     |      11      |    95    |     72      |       22       |     68     |\n",
            "|         ['sentiment_to_star', 'review_length']         |  0.673   |    57     |      24      |    81    |     72      |       22       |     68     |\n",
            "| ['sentiment_to_star', 'review_length', 'grade_number'] |  0.667   |    53     |      27      |    82    |     72      |       22       |     68     |\n",
            "|                    ['grade_number']                    |  0.562   |    95     |      0       |    67    |     72      |       22       |     68     |\n",
            "|           ['review_length', 'grade_number']            |  0.531   |    93     |      24      |    45    |     72      |       22       |     68     |\n",
            "|                   ['review_length']                    |  0.389   |    15     |      1       |   146    |     72      |       22       |     68     |\n",
            "+--------------------------------------------------------+----------+-----------+--------------+----------+-------------+----------------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tree Regressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tabulate import tabulate\n",
        "feature_sets = [\n",
        "    ['sentiment_to_star'],\n",
        "    ['review_length'],\n",
        "    ['grade_number'],\n",
        "    ['sentiment_to_star', 'review_length'],\n",
        "    ['sentiment_to_star', 'grade_number'],\n",
        "    ['review_length', 'grade_number'],\n",
        "    ['sentiment_to_star', 'review_length', 'grade_number']\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for features in feature_sets:\n",
        "    X_train = train_data[features]\n",
        "    y_train = train_data['rating']\n",
        "    X_test = test_data[features]\n",
        "    y_test = test_data['rating']\n",
        "\n",
        "\n",
        "    tree_model = DecisionTreeRegressor(max_depth=4, random_state=42)\n",
        "    tree_model.fit(X_train, y_train)\n",
        "    predicted_rating = tree_model.predict(X_test)\n",
        "    r2 = r2_score(y_test, predicted_rating)\n",
        "    rmse = mean_squared_error(y_test, predicted_rating)\n",
        "    average_predicted_rating = predicted_rating.mean()\n",
        "\n",
        "    results.append({\n",
        "        'Features': features,\n",
        "        'R²': round(r2, 3),\n",
        "        'RMSE': round(rmse, 2),\n",
        "        'Average Predicted Rating': round(average_predicted_rating, 2)\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by='R²', ascending=False)\n",
        "print(tabulate(results_df, headers='keys', tablefmt='pretty', showindex=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oS6-32RYmBCF",
        "outputId": "733751e2-edbb-4f48-daa1-64acc4569ed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------+--------+------+--------------------------+\n",
            "|                        Features                        |   R²   | RMSE | Average Predicted Rating |\n",
            "+--------------------------------------------------------+--------+------+--------------------------+\n",
            "|                 ['sentiment_to_star']                  | 0.452  | 1.37 |           2.92           |\n",
            "|         ['sentiment_to_star', 'grade_number']          | 0.424  | 1.43 |           2.95           |\n",
            "| ['sentiment_to_star', 'review_length', 'grade_number'] | 0.353  | 1.61 |           3.0            |\n",
            "|         ['sentiment_to_star', 'review_length']         | 0.305  | 1.73 |           2.89           |\n",
            "|                    ['grade_number']                    | 0.112  | 2.21 |           3.02           |\n",
            "|           ['review_length', 'grade_number']            | 0.043  | 2.39 |           3.03           |\n",
            "|                   ['review_length']                    | -0.045 | 2.6  |           2.86           |\n",
            "+--------------------------------------------------------+--------+------+--------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear regession\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tabulate import tabulate\n",
        "feature_sets = [\n",
        "    ['sentiment_to_star'],\n",
        "    ['review_length'],\n",
        "    ['grade_number'],\n",
        "    ['sentiment_to_star', 'review_length'],\n",
        "    ['sentiment_to_star', 'grade_number'],\n",
        "    ['review_length', 'grade_number'],\n",
        "    ['sentiment_to_star', 'review_length', 'grade_number']\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for features in feature_sets:\n",
        "  X_train = train_data[features]\n",
        "  y_train = train_data['rating']\n",
        "  X_test = test_data[features]\n",
        "  y_test = test_data['rating']\n",
        "\n",
        "\n",
        "  linear_model = LinearRegression()\n",
        "  linear_model.fit(X_train, y_train)\n",
        "  predicted_ratings = linear_model.predict(X_test)\n",
        "  r2 = r2_score(y_test, predicted_ratings)\n",
        "  rmse = mean_squared_error(y_test, predicted_ratings)\n",
        "  average_predicted_rating = predicted_ratings.mean()\n",
        "  results.append({\n",
        "        'Features': features,\n",
        "        'R²': round(r2, 3),\n",
        "        'RMSE': round(rmse, 2),\n",
        "        'Average Predicted Rating': round(average_predicted_rating, 2)\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by='R²', ascending=False)\n",
        "print(tabulate(results_df, headers='keys', tablefmt='pretty', showindex=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECOzhYux8nY9",
        "outputId": "41c6528d-d5bc-4b64-dfa9-a5220634506b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------+-------+------+--------------------------+\n",
            "|                        Features                        |  R²   | RMSE | Average Predicted Rating |\n",
            "+--------------------------------------------------------+-------+------+--------------------------+\n",
            "| ['sentiment_to_star', 'review_length', 'grade_number'] | 0.543 | 1.14 |           2.96           |\n",
            "|         ['sentiment_to_star', 'grade_number']          | 0.528 | 1.18 |           2.96           |\n",
            "|         ['sentiment_to_star', 'review_length']         | 0.498 | 1.25 |           2.94           |\n",
            "|                 ['sentiment_to_star']                  | 0.479 | 1.3  |           2.92           |\n",
            "|           ['review_length', 'grade_number']            | 0.118 | 2.2  |           2.97           |\n",
            "|                    ['grade_number']                    | 0.117 | 2.2  |           2.97           |\n",
            "|                   ['review_length']                    | 0.005 | 2.48 |           2.91           |\n",
            "+--------------------------------------------------------+-------+------+--------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using random forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tabulate import tabulate\n",
        "feature_sets = [\n",
        "    ['sentiment_to_star'],\n",
        "    ['review_length'],\n",
        "    ['grade_number'],\n",
        "    ['sentiment_to_star', 'review_length'],\n",
        "    ['sentiment_to_star', 'grade_number'],\n",
        "    ['review_length', 'grade_number'],\n",
        "    ['sentiment_to_star', 'review_length', 'grade_number']]\n",
        "results = []\n",
        "actual_counts = test_data['rating_category'].value_counts()\n",
        "for features in feature_sets:\n",
        "    X_train = train_data[features]\n",
        "    X_test = test_data[features]\n",
        "    y_train = train_data['rating_category']\n",
        "    y_test = test_data['rating_category']\n",
        "\n",
        "    model = RandomForestClassifier(max_depth=4, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    predicted_rating = model.predict(X_test)\n",
        "    pred_counts = pd.Series(predicted_rating).value_counts()\n",
        "    accuracy = accuracy_score(y_test, predicted_rating)\n",
        "    results.append({\n",
        "     'Features': features,\n",
        "     'Accuracy': round(accuracy, 3),\n",
        "     'Pred Good': pred_counts.get('good', 0),\n",
        "     'Pred Neutral': pred_counts.get('neutral', 0),\n",
        "     'Pred Bad': pred_counts.get('bad', 0),\n",
        "     'Actual Good': actual_counts.get('good', 0),\n",
        "     'Actual Neutral': actual_counts.get('neutral', 0),\n",
        "     'Actual Bad': actual_counts.get('bad', 0),\n",
        "})\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by='Accuracy', ascending=False)\n",
        "print(tabulate(results_df, headers='keys', tablefmt='pretty', showindex=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPYRcPpatstu",
        "outputId": "e34fcbed-3092-4e0f-eb7f-0f7cb49ef70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------+----------+-----------+--------------+----------+-------------+----------------+------------+\n",
            "|                        Features                        | Accuracy | Pred Good | Pred Neutral | Pred Bad | Actual Good | Actual Neutral | Actual Bad |\n",
            "+--------------------------------------------------------+----------+-----------+--------------+----------+-------------+----------------+------------+\n",
            "|                 ['sentiment_to_star']                  |  0.691   |    57     |      0       |   105    |     72      |       22       |     68     |\n",
            "|         ['sentiment_to_star', 'grade_number']          |  0.691   |    56     |      11      |    95    |     72      |       22       |     68     |\n",
            "|         ['sentiment_to_star', 'review_length']         |  0.691   |    60     |      9       |    93    |     72      |       22       |     68     |\n",
            "| ['sentiment_to_star', 'review_length', 'grade_number'] |  0.691   |    60     |      8       |    94    |     72      |       22       |     68     |\n",
            "|           ['review_length', 'grade_number']            |  0.568   |    94     |      1       |    67    |     72      |       22       |     68     |\n",
            "|                    ['grade_number']                    |  0.562   |    95     |      0       |    67    |     72      |       22       |     68     |\n",
            "|                   ['review_length']                    |  0.401   |    46     |      4       |   112    |     72      |       22       |     68     |\n",
            "+--------------------------------------------------------+----------+-----------+--------------+----------+-------------+----------------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using random forest\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tabulate import tabulate\n",
        "feature_sets = [\n",
        "    ['sentiment_to_star'],\n",
        "    ['review_length'],\n",
        "    ['grade_number'],\n",
        "    ['sentiment_to_star', 'review_length'],\n",
        "    ['sentiment_to_star', 'grade_number'],\n",
        "    ['review_length', 'grade_number'],\n",
        "    ['sentiment_to_star', 'review_length', 'grade_number']]\n",
        "result = []\n",
        "\n",
        "\n",
        "for features in feature_sets:\n",
        "  X_train = train_data[features]\n",
        "  y_train = train_data['rating']\n",
        "  X_test = test_data[features]\n",
        "  y_test = test_data['rating']\n",
        "\n",
        "  forest_model = RandomForestRegressor(n_estimators=100, max_depth=4, random_state=42)\n",
        "\n",
        "  forest_model.fit(X_train, y_train)\n",
        "  predicted_ratings = forest_model.predict(X_test)\n",
        "  r2 = r2_score(y_test, predicted_ratings)\n",
        "  rmse = mean_squared_error(y_test, predicted_ratings)\n",
        "  average_predicted_rating = predicted_ratings.mean()\n",
        "  result.append({\n",
        "      'Features': features,\n",
        "      'R²': round(r2, 3),\n",
        "      'RMSE': round(rmse, 2),\n",
        "      'Average Predicted Rating': round(average_predicted_rating, 2)\n",
        "  })\n",
        "results_df = pd.DataFrame(result)\n",
        "results_df = results_df.sort_values(by='R²', ascending=False)\n",
        "print(tabulate(results_df, headers='keys', tablefmt='pretty', showindex=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvEtLBzZlZxZ",
        "outputId": "b4888808-0419-43c1-c42b-469ce7e5ccd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------+--------+------+--------------------------+\n",
            "|                        Features                        |   R²   | RMSE | Average Predicted Rating |\n",
            "+--------------------------------------------------------+--------+------+--------------------------+\n",
            "|                 ['sentiment_to_star']                  | 0.453  | 1.36 |           2.93           |\n",
            "| ['sentiment_to_star', 'review_length', 'grade_number'] | 0.439  | 1.4  |           3.0            |\n",
            "|         ['sentiment_to_star', 'review_length']         | 0.437  | 1.4  |           2.94           |\n",
            "|         ['sentiment_to_star', 'grade_number']          | 0.418  | 1.45 |           2.98           |\n",
            "|                    ['grade_number']                    | 0.112  | 2.21 |           3.04           |\n",
            "|           ['review_length', 'grade_number']            | 0.086  | 2.28 |           3.01           |\n",
            "|                   ['review_length']                    | -0.037 | 2.58 |           2.88           |\n",
            "+--------------------------------------------------------+--------+------+--------------------------+\n"
          ]
        }
      ]
    }
  ]
}